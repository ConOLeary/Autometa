########## 6 / 4 / 2021 ##########
> Cars are now being trained on a rotation of 3 maps. This has meant that the cars need to be a lot more verstaile, something which my training parameters have not accomplished yet.

> The structure of the code in PyCar.py being an afterthought is starting to take its toll on development; at this stage every new feature I add seems to require significant refactoring.
That said, I still think head first was the best way to approach this project, as any substantial structuring would have become obsolete fast as my approach, and even my goal, change as I learn more.

########## 31 / 3 / 2021 ##########
> Red cars will be fast, green cars will turn fast

########## 22 / 3 / 2021 ##########
> Would seem older-school neuro net apporaches like NEAT are more plausible to 'retail' learners, in that they produce a fesible results without a great volume of learning, but that their abilty ceiling is much more limited then contemporary reinforcement learning approaches designed for powerful GPUs;
ie everything that can be solved through NEAT can be solved in a relatively short period of time (eg hours on a standard computer, rather then days or weeks).
NEAT was 
########## 20 / 3 / 2021 ##########
> "Min-maxing" is the boogie man. This usually has a tangibly unhealthy effect on the competitive community of a game once the "honey moon period" of the game / patch of the game has passed, and the best ways to min-max the game have been discovered and subsequently adopted widely.

> NEAT is apparently OP and is offering much more promising results then deep Q-learning (or whatever the first approach used). I have decided that I shouldn't expect myself to understand the underlying algorithm thoroughly.

########## 12 / 2 / 2021 ##########
> Reinforcement learning seems to be what is needed

########## 4 / 2 / 2021 ##########
> Bots could be deep learned to find the most optimal ways to play the game rather then using human data. Means of course there will be more data,
    but more importantly, frequency of choices can be assumed to be purely based on starategic optimisation. With human data, it would have to be
    considered that certain choices may be made because these choices involve the use of more-fun features in the game.